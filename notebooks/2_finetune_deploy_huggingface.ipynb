{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Finetuning HuggingFace models with Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install or upgrade sagemaker sdk and sagemaker debugger sdk\n",
    "# Ignore warnings related to pip\n",
    "!pip install -Uq sagemaker smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-08-23 21:34:09.229 user-1-kernel:329 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "from IPython.display import FileLink\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import TrainingJobAnalytics\n",
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile, DebuggerHookConfig\n",
    "from sagemaker.huggingface import HuggingFace, HuggingFaceModel, HuggingFacePredictor\n",
    "\n",
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::829802005956:role/service-role/AmazonSageMaker-ExecutionRole-12345\n",
      "sagemaker bucket: sagemaker-us-east-1-829802005956\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# permissions\n",
    "sess = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker_huggingface_workshop\"\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a HuggingFace Transformers fine-tuning script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training script that performs fine tuning is located here: `src/train.py`\n",
    "Navigate to the source code location and open the `train.py` file. You can also go through it's contents by executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_dataset\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m accuracy_score, precision_recall_fscore_support\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtrainer_utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m get_last_checkpoint\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m(args):\n",
      "        \n",
      "    \u001b[37m# Hyper-parameters\u001b[39;49;00m\n",
      "    training_dir     = args.training_dir\n",
      "    test_dir         = args.test_dir\n",
      "    output_dir       = args.output_dir\n",
      "    output_data_dir  = args.output_data_dir\n",
      "    model_dir        = args.model_dir\n",
      "\n",
      "    model_name       = args.model_name\n",
      "    epochs           = args.epochs\n",
      "    train_batch_size = args.train_batch_size\n",
      "    eval_batch_size  = args.eval_batch_size\n",
      "    warmup_steps     = args.warmup_steps\n",
      "    learning_rate    = args.learning_rate\n",
      "    \n",
      "    \u001b[37m# Set up logging\u001b[39;49;00m\n",
      "    logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "    logger.info(sys.argv)\n",
      "    \n",
      "    logging.basicConfig(\n",
      "        level=logging.getLevelName(\u001b[33m\"\u001b[39;49;00m\u001b[33mINFO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\n",
      "        handlers=[logging.StreamHandler(sys.stdout)],\n",
      "        \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(name)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "   \n",
      "    \u001b[37m# download tokenizer\u001b[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
      "    \n",
      "    \u001b[37m# Load dataset\u001b[39;49;00m\n",
      "    train_file    = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{training_dir}\u001b[39;49;00m\u001b[33m/train.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    validate_file = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{test_dir}\u001b[39;49;00m\u001b[33m/validate.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \n",
      "    dataset = load_dataset(\u001b[33m'\u001b[39;49;00m\u001b[33mcsv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, data_files={\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_file,\n",
      "                                             \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: validate_file})\n",
      "    train_dataset = dataset[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    test_dataset = dataset[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    \n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded train_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33mlen(train_dataset)}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded test_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33mlen(test_dataset)}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# tokenizer helper function\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtokenize\u001b[39;49;00m(batch):\n",
      "        \u001b[34mreturn\u001b[39;49;00m tokenizer(batch[\u001b[33m'\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], padding=\u001b[33m'\u001b[39;49;00m\u001b[33mmax_length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, truncation=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# tokenize dataset\u001b[39;49;00m\n",
      "    train_dataset = train_dataset.map(tokenize, batched=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    test_dataset = test_dataset.map(tokenize, batched=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# set format for pytorch\u001b[39;49;00m\n",
      "    train_dataset =  train_dataset.rename_column(\u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mlabels\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    train_dataset.set_format(\u001b[33m'\u001b[39;49;00m\u001b[33mtorch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, columns=[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlabels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    test_dataset = test_dataset.rename_column(\u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mlabels\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    test_dataset.set_format(\u001b[33m'\u001b[39;49;00m\u001b[33mtorch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, columns=[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mlabels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded train_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33mlen(train_dataset)}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded test_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33mlen(test_dataset)}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# compute metrics function for classification\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcompute_metrics\u001b[39;49;00m(pred):\n",
      "        labels = pred.label_ids\n",
      "        preds = pred.predictions.argmax(-\u001b[34m1\u001b[39;49;00m)\n",
      "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mweighted\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        acc = accuracy_score(labels, preds)\n",
      "        \u001b[34mreturn\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: acc, \u001b[33m\"\u001b[39;49;00m\u001b[33mf1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: f1, \u001b[33m\"\u001b[39;49;00m\u001b[33mprecision\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: precision, \u001b[33m\"\u001b[39;49;00m\u001b[33mrecall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: recall}\n",
      "\n",
      "    \u001b[37m# download model from model hub\u001b[39;49;00m\n",
      "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=\u001b[34m5\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# define training args\u001b[39;49;00m\n",
      "    training_args = TrainingArguments(\n",
      "        output_dir                  = output_dir,\n",
      "        num_train_epochs            = epochs,\n",
      "        per_device_train_batch_size = train_batch_size,\n",
      "        per_device_eval_batch_size  = eval_batch_size,\n",
      "        warmup_steps                = warmup_steps,\n",
      "        evaluation_strategy         = \u001b[33m\"\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        logging_dir                 = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{output_data_dir}\u001b[39;49;00m\u001b[33m/logs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    )\n",
      "\n",
      "    \u001b[37m# create Trainer instance\u001b[39;49;00m\n",
      "    trainer = Trainer(\n",
      "        model           = model,\n",
      "        args            = training_args,\n",
      "        compute_metrics = compute_metrics,\n",
      "        train_dataset   = train_dataset,\n",
      "        eval_dataset    = test_dataset,\n",
      "    )\n",
      "\n",
      "    \u001b[37m# train model\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m get_last_checkpoint(output_dir) \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m:\n",
      "        logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33m***** continue training *****\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        trainer.train(resume_from_checkpoint=output_dir)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        trainer.train()\n",
      "    \u001b[37m# evaluate model\u001b[39;49;00m\n",
      "    eval_result = trainer.evaluate(eval_dataset=test_dataset)\n",
      "\n",
      "    \u001b[37m# writes eval result to file which can be accessed later in s3 ouput\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(output_data_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33meval_results.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m writer:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m***** Eval results *****\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[34mfor\u001b[39;49;00m key, value \u001b[35min\u001b[39;49;00m \u001b[36msorted\u001b[39;49;00m(eval_result.items()):\n",
      "            writer.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{key}\u001b[39;49;00m\u001b[33m = \u001b[39;49;00m\u001b[33m{value}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Saves the model to s3\u001b[39;49;00m\n",
      "    trainer.save_model(model_dir)\n",
      "    tokenizer.save_pretrained(model_dir)\n",
      "    \n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eval-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--warmup_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m500\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34m5e-5\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--output_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,  default=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/checkpoints\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--training_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--test_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    args, _ = parser.parse_known_args()\n",
      "    \n",
      "    main(args)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an HuggingFace Estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 32,\n",
    "                 'model_name':'distilbert-base-uncased',\n",
    "                 }\n",
    "\n",
    "metric_definitions=[\n",
    "    {'Name': 'learning_rate',           'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss',               'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy',           'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_f1',                 'Regex': \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision',          'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall',             'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_runtime',            'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch',                   'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure rules\n",
    "\n",
    "We specify the following rules:\n",
    "\n",
    "* loss_not_decreasing: checks if loss is decreasing and triggers if the loss has not decreased by a certain percentage in the last few iterations\n",
    "* LowGPUUtilization: checks if GPU is under-utilizated\n",
    "* ProfilerReport: runs the entire set of performance rules and create a final output report with further insights and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a Profiler rule object\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following configuration will capture system metrics at 500 milliseconds. The system metrics include utilization per CPU, GPU, memory utilization per CPU, GPU as well I/O and network.\n",
    "\n",
    "Debugger will capture detailed profiling information from step 5 to step 15. This information includes Horovod metrics, dataloading, preprocessing, operators running on CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a profiler configuration\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, \n",
    "    framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 uri where our checkpoints will be uploaded during training\n",
    "job_name    = f'huggingface-spot-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "checkpoint_s3_uri = f's3://{bucket}/{prefix}/{job_name}/checkpoints'\n",
    "output_path = f's3://{bucket}/{prefix}/training_jobs'\n",
    "\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(entry_point          = 'train.py',\n",
    "                                    source_dir           = 'src',\n",
    "                                    output_path          = f'{output_path}/',\n",
    "                                    code_location        = output_path,\n",
    "                                    role                 = role,\n",
    "                                    base_job_name        = job_name,\n",
    "                                    checkpoint_s3_uri    = checkpoint_s3_uri,\n",
    "                                    instance_type        = 'ml.p3.2xlarge',\n",
    "                                    instance_count       = 1,\n",
    "                                    transformers_version = '4.6',\n",
    "                                    pytorch_version      = '1.7',\n",
    "                                    py_version           = 'py36',\n",
    "                                    hyperparameters      = hyperparameters,\n",
    "                                    metric_definitions   = metric_definitions,\n",
    "                                    # Debugger-specific parameters\n",
    "                                    profiler_config      = profiler_config,\n",
    "                                    rules                = rules\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the fine-tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-23 21:34:30 Starting - Starting the training job...\n",
      "2021-08-23 21:34:56 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "......\n",
      "2021-08-23 21:35:56 Starting - Preparing the instances for training............\n",
      "2021-08-23 21:38:01 Downloading - Downloading input data\n",
      "2021-08-23 21:38:01 Training - Downloading the training image.................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:42,965 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:42,988 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:49,213 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:49,726 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"train_batch_size\": 32,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-spot-2021-08-23-21-34-26-2021-08-23-21-34-29-614\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-829802005956/sagemaker_huggingface_workshop/training_jobs/huggingface-spot-2021-08-23-21-34-26-2021-08-23-21-34-29-614/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-829802005956/sagemaker_huggingface_workshop/training_jobs/huggingface-spot-2021-08-23-21-34-26-2021-08-23-21-34-29-614/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-spot-2021-08-23-21-34-26-2021-08-23-21-34-29-614\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-829802005956/sagemaker_huggingface_workshop/training_jobs/huggingface-spot-2021-08-23-21-34-26-2021-08-23-21-34-29-614/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2021-08-23 21:40:58 Training - Training image download completed. Training in progress.\u001b[34m2021-08-23 21:40:54,615 - filelock - INFO - Lock 140068973821008 acquired on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,641 - filelock - INFO - Lock 140068973821008 released on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,661 - filelock - INFO - Lock 140068973821568 acquired on /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,687 - filelock - INFO - Lock 140068973821568 released on /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,706 - filelock - INFO - Lock 140068973821512 acquired on /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,747 - filelock - INFO - Lock 140068973821512 released on /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,806 - filelock - INFO - Lock 140068973821568 acquired on /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,827 - filelock - INFO - Lock 140068973821568 released on /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:54,903 - datasets.builder - WARNING - Using custom data configuration default-735c45c4e600da54\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-735c45c4e600da54/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-735c45c4e600da54/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:55,036 - __main__ - INFO -  loaded train_dataset length is: 13584\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:55,036 - __main__ - INFO -  loaded test_dataset length is: 4528\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:57,982 - __main__ - INFO -  loaded train_dataset length is: 13584\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:57,982 - __main__ - INFO -  loaded test_dataset length is: 4528\u001b[0m\n",
      "\u001b[34m2021-08-23 21:40:58,024 - filelock - INFO - Lock 140068966718824 acquired on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34m2021-08-23 21:41:02,893 - filelock - INFO - Lock 140068966718824 released on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.179 algo-1:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.343 algo-1:25 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.345 algo-1:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.347 algo-1:25 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.349 algo-1:25 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.899 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.900 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.901 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.901 algo-1:25 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.902 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.902 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.903 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.903 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.904 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.904 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.905 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.906 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.906 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.907 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.907 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.908 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.908 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.908 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.909 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.909 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.910 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.911 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.911 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.911 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.912 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.912 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.913 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.913 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.914 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.914 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.915 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.915 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.916 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.916 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.917 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.917 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.918 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.918 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.919 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.919 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.920 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.920 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.921 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.921 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.922 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.922 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.923 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.923 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.924 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.924 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.925 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.925 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.926 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.926 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.927 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.927 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.928 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.928 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.928 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.929 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.930 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.930 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.931 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.931 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.932 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.932 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.933 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.934 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.934 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.935 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.935 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.936 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.937 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.937 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.938 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.938 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.939 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.940 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.940 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.941 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.941 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.942 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.942 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.943 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.943 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.944 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.944 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.945 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.945 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.945 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.946 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.946 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.947 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.947 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.948 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.948 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.949 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.949 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.950 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.950 algo-1:25 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.951 algo-1:25 INFO hook.py:591] name:pre_classifier.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.951 algo-1:25 INFO hook.py:591] name:pre_classifier.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.951 algo-1:25 INFO hook.py:591] name:classifier.weight count_params:3840\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.952 algo-1:25 INFO hook.py:591] name:classifier.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.952 algo-1:25 INFO hook.py:593] Total Trainable Params: 66957317\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.953 algo-1:25 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.955 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/prestepzero-*-start-1629754868344237.2_global-0-stepstart-1629754868954961.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:08.967 algo-1:25 INFO hook.py:488] Hook is writing from the hook with pid: 25\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:10.297 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-0-stepstart-1629754868962614.8_global-0-forwardpassend-1629754870295806.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:11.296 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-0-forwardpassend-1629754870300616.8_global-1-stepstart-1629754871292060.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:15.885 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-1-stepstart-1629754871305231.8_global-1-forwardpassend-1629754875884946.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:16.864 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-1-forwardpassend-1629754875890312.5_global-2-stepstart-1629754876863759.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:20.851 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-2-stepstart-1629754876869724.5_global-2-forwardpassend-1629754880851219.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:21.808 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-2-forwardpassend-1629754880854381.5_global-3-stepstart-1629754881806184.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:25.773 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-3-stepstart-1629754881815789.0_global-3-forwardpassend-1629754885772940.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:26.763 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-3-forwardpassend-1629754885775634.2_global-4-stepstart-1629754886758381.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:30.835 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-4-stepstart-1629754886769335.2_global-4-forwardpassend-1629754890834429.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:31.816 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-4-forwardpassend-1629754890837700.5_global-5-stepstart-1629754891814143.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:35.828 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-5-stepstart-1629754891823249.5_global-5-forwardpassend-1629754895828165.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:36.806 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-5-forwardpassend-1629754895831025.8_global-6-stepstart-1629754896802689.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:40.737 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-6-stepstart-1629754896813927.2_global-6-forwardpassend-1629754900736956.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:41.705 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-6-forwardpassend-1629754900739890.0_global-7-stepstart-1629754901703255.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:45.764 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-7-stepstart-1629754901712830.2_global-7-forwardpassend-1629754905763668.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:46.724 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-7-forwardpassend-1629754905766728.0_global-8-stepstart-1629754906723490.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:50.781 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-8-stepstart-1629754906730923.0_global-8-forwardpassend-1629754910780540.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:51.748 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-8-forwardpassend-1629754910783027.2_global-9-stepstart-1629754911742917.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:55.817 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-9-stepstart-1629754911753707.0_global-9-forwardpassend-1629754915816676.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-08-23 21:41:56.778 algo-1:25 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/25-algo-1/global-9-forwardpassend-1629754915819375.5_global-10-stepstart-1629754916775928.2/python_stats.\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.8025973439216614, 'eval_accuracy': 0.6643109540636042, 'eval_f1': 0.634701166554232, 'eval_precision': 0.6210450447136964, 'eval_recall': 0.6643109540636042, 'eval_runtime': 30.9307, 'eval_samples_per_second': 146.392, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 335.5067, 'train_samples_per_second': 1.267, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]#015Downloading: 100%|| 442/442 [00:00<00:00, 608kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|| 232k/232k [00:00<00:00, 42.8MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading: 100%|| 466k/466k [00:00<00:00, 34.1MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]#015Downloading: 100%|| 28.0/28.0 [00:00<00:00, 40.2kB/s]\u001b[0m\n",
      "\u001b[34m#0150 tables [00:00, ? tables/s]#015                            #015#0150 tables [00:00, ? tables/s]#015                            #015#015  0%|          | 0/14 [00:00<?, ?ba/s]#015  7%|         | 1/14 [00:00<00:03,  3.46ba/s]#015 14%|        | 2/14 [00:00<00:02,  4.05ba/s]#015 21%|       | 3/14 [00:00<00:02,  4.60ba/s]#015 29%|       | 4/14 [00:00<00:01,  5.08ba/s]#015 36%|      | 5/14 [00:00<00:01,  5.52ba/s]#015 43%|     | 6/14 [00:01<00:01,  5.22ba/s]#015 50%|     | 7/14 [00:01<00:01,  5.60ba/s]#015 57%|    | 8/14 [00:01<00:01,  5.95ba/s]#015 64%|   | 9/14 [00:01<00:00,  6.19ba/s]#015 71%|  | 10/14 [00:01<00:00,  6.37ba/s]#015 79%|  | 11/14 [00:01<00:00,  6.48ba/s]#015 86%| | 12/14 [00:01<00:00,  6.30ba/s]#015 93%|| 13/14 [00:02<00:00,  6.43ba/s]#015100%|| 14/14 [00:02<00:00,  6.27ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?ba/s]#015 20%|        | 1/5 [00:00<00:00,  5.97ba/s]#015 40%|      | 2/5 [00:00<00:00,  6.21ba/s]#015 60%|    | 3/5 [00:00<00:00,  6.41ba/s]#015 80%|  | 4/5 [00:00<00:00,  6.48ba/s]#015100%|| 5/5 [00:00<00:00,  7.27ba/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]#015Downloading:   2%|         | 4.61M/268M [00:00<00:05, 46.1MB/s]#015Downloading:   4%|         | 9.96M/268M [00:00<00:05, 48.1MB/s]#015Downloading:   6%|         | 15.4M/268M [00:00<00:05, 49.8MB/s]#015Downloading:   8%|         | 20.9M/268M [00:00<00:04, 51.3MB/s]#015Downloading:  10%|         | 26.3M/268M [00:00<00:04, 52.1MB/s]#015Downloading:  12%|        | 31.9M/268M [00:00<00:04, 53.3MB/s]#015Downloading:  14%|        | 37.6M/268M [00:00<00:04, 54.2MB/s]#015Downloading:  16%|        | 43.0M/268M [00:00<00:04, 54.3MB/s]#015Downloading:  18%|        | 48.7M/268M [00:00<00:03, 54.9MB/s]#015Downloading:  20%|        | 54.3M/268M [00:01<00:03, 55.4MB/s]#015Downloading:  22%|       | 60.0M/268M [00:01<00:03, 55.9MB/s]#015Downloading:  24%|       | 65.6M/268M [00:01<00:03, 55.3MB/s]#015Downloading:  27%|       | 71.6M/268M [00:01<00:03, 56.6MB/s]#015Downloading:  29%|       | 77.6M/268M [00:01<00:03, 57.6MB/s]#015Downloading:  31%|       | 83.6M/268M [00:01<00:03, 58.3MB/s]#015Downloading:  33%|      | 89.6M/268M [00:01<00:03, 58.9MB/s]#015Downloading:  36%|      | 95.6M/268M [00:01<00:02, 59.4MB/s]#015Downloading:  38%|      | 102M/268M [00:01<00:02, 59.4MB/s] #015Downloading:  40%|      | 108M/268M [00:01<00:02, 59.7MB/s]#015Downloading:  42%|     | 114M/268M [00:02<00:02, 58.6MB/s]#015Downloading:  45%|     | 119M/268M [00:02<00:02, 56.7MB/s]#015Downloading:  47%|     | 125M/268M [00:02<00:02, 56.2MB/s]#015Downloading:  49%|     | 131M/268M [00:02<00:02, 49.5MB/s]#015Downloading:  51%|     | 136M/268M [00:02<00:02, 50.9MB/s]#015Downloading:  53%|    | 142M/268M [00:02<00:02, 51.4MB/s]#015Downloading:  55%|    | 147M/268M [00:02<00:02, 53.0MB/s]#015Downloading:  57%|    | 153M/268M [00:02<00:02, 53.9MB/s]#015Downloading:  59%|    | 159M/268M [00:02<00:01, 55.0MB/s]#015Downloading:  61%|   | 164M/268M [00:02<00:01, 55.8MB/s]#015Downloading:  64%|   | 170M/268M [00:03<00:01, 56.4MB/s]#015Downloading:  66%|   | 176M/268M [00:03<00:01, 55.4MB/s]#015Downloading:  68%|   | 181M/268M [00:03<00:01, 52.4MB/s]#015Downloading:  70%|   | 187M/268M [00:03<00:01, 52.6MB/s]#015Downloading:  72%|  | 192M/268M [00:03<00:01, 48.9MB/s]#015Downloading:  74%|  | 198M/268M [00:03<00:01, 51.3MB/s]#015Downloading:  76%|  | 204M/268M [00:03<00:01, 53.0MB/s]#015Downloading:  78%|  | 209M/268M [00:03<00:01, 53.8MB/s]#015Downloading:  80%|  | 215M/268M [00:03<00:00, 54.9MB/s]#015Downloading:  82%| | 221M/268M [00:04<00:00, 55.8MB/s]#015Downloading:  85%| | 226M/268M [00:04<00:00, 56.4MB/s]#015Downloading:  87%| | 232M/268M [00:04<00:00, 57.1MB/s]#015Downloading:  89%| | 238M/268M [00:04<00:00, 57.5MB/s]#015Downloading:  91%| | 244M/268M [00:04<00:00, 57.9MB/s]#015Downloading:  93%|| 250M/268M [00:04<00:00, 58.1MB/s]#015Downloading:  96%|| 256M/268M [00:04<00:00, 58.6MB/s]#015Downloading:  98%|| 262M/268M [00:04<00:00, 58.8MB/s]#015Downloading: 100%|| 268M/268M [00:04<00:00, 58.6MB/s]#015Downloading: 100%|| 268M/268M [00:04<00:00, 55.5MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/425 [00:00<?, ?it/s]#015  0%|          | 1/425 [00:03<21:13,  3.00s/it]#015  0%|          | 2/425 [00:08<26:36,  3.77s/it]#015  1%|          | 3/425 [00:13<29:02,  4.13s/it]#015  1%|          | 4/425 [00:18<30:42,  4.38s/it]#015  1%|          | 5/425 [00:23<32:03,  4.58s/it]#015  1%|         | 6/425 [00:28<32:50,  4.70s/it]#015  2%|         | 7/425 [00:33<33:09,  4.76s/it]#015  2%|         | 8/425 [00:38<33:37,  4.84s/it]#015  2%|         | 9/425 [00:43<33:55,  4.89s/it]#015  2%|         | 10/425 [00:48<34:07,  4.93s/it]#015  3%|         | 11/425 [00:51<30:38,  4.44s/it]#015  3%|         | 12/425 [00:52<22:38,  3.29s/it]#015  3%|         | 13/425 [00:52<17:02,  2.48s/it]#015  3%|         | 14/425 [00:53<13:11,  1.92s/it]#015  4%|         | 15/425 [00:54<10:26,  1.53s/it]#015  4%|         | 16/425 [00:54<08:35,  1.26s/it]#015  4%|         | 17/425 [00:55<07:21,  1.08s/it]#015  4%|         | 18/425 [00:56<06:23,  1.06it/s]#015  4%|         | 19/425 [00:56<05:44,  1.18it/s]#015  5%|         | 20/425 [00:57<05:16,  1.28it/s]#015  5%|         | 21/425 [00:57<04:53,  1.37it/s]#015  5%|         | 22/425 [00:58<04:37,  1.45it/s]#015  5%|         | 23/425 [00:59<04:26,  1.51it/s]#015  6%|         | 24/425 [00:59<04:18,  1.55it/s]#015  6%|         | 25/425 [01:00<04:11,  1.59it/s]#015  6%|         | 26/425 [01:00<04:07,  1.61it/s]#015  6%|         | 27/425 [01:01<04:07,  1.61it/s]#015  7%|         | 28/425 [01:02<04:04,  1.62it/s]#015  7%|         | 29/425 [01:02<04:02,  1.64it/s]#015  7%|         | 30/425 [01:03<04:01,  1.64it/s]#015  7%|         | 31/425 [01:04<04:02,  1.62it/s]#015  8%|         | 32/425 [01:04<04:02,  1.62it/s]#015  8%|         | 33/425 [01:05<04:00,  1.63it/s]#015  8%|         | 34/425 [01:05<04:01,  1.62it/s]#015  8%|         | 35/425 [01:06<03:59,  1.63it/s]#015  8%|         | 36/425 [01:07<03:56,  1.64it/s]#015  9%|         | 37/425 [01:07<03:54,  1.66it/s]#015  9%|         | 38/425 [01:08<04:00,  1.61it/s]#015  9%|         | 39/425 [01:08<03:59,  1.61it/s]#015  9%|         | 40/425 [01:09<03:56,  1.63it/s]#015 10%|         | 41/425 [01:10<03:54,  1.64it/s]#015 10%|         | 42/425 [01:10<03:51,  1.65it/s]#015 10%|         | 43/425 [01:11<03:50,  1.66it/s]#015 10%|         | 44/425 [01:11<03:50,  1.65it/s]#015 11%|         | 45/425 [01:12<03:48,  1.66it/s]#015 11%|         | 46/425 [01:13<03:48,  1.66it/s]#015 11%|         | 47/425 [01:13<03:46,  1.67it/s]#015 11%|        | 48/425 [01:14<03:46,  1.67it/s]#015 12%|        | 49/425 [01:14<03:45,  1.66it/s]#015 12%|        | 50/425 [01:15<03:45,  1.66it/s]#015 12%|        | 51/425 [01:16<03:44,  1.67it/s]#015 12%|        | 52/425 [01:16<03:43,  1.67it/s]#015 12%|        | 53/425 [01:17<03:44,  1.66it/s]#015 13%|        | 54/425 [01:17<03:41,  1.68it/s]#015 13%|        | 55/425 [01:18<03:41,  1.67it/s]#015 13%|        | 56/425 [01:19<03:41,  1.67it/s]#015 13%|        | 57/425 [01:19<03:40,  1.67it/s]#015 14%|        | 58/425 [01:20<03:39,  1.67it/s]#015 14%|        | 59/425 [01:20<03:39,  1.67it/s]#015 14%|        | 60/425 [01:21<03:39,  1.66it/s]#015 14%|        | 61/425 [01:22<03:41,  1.65it/s]#015 15%|        | 62/425 [01:22<03:39,  1.66it/s]#015 15%|        | 63/425 [01:23<03:37,  1.67it/s]#015 15%|        | 64/425 [01:23<03:37,  1.66it/s]#015 15%|        | 65/425 [01:24<03:37,  1.66it/s]#015 16%|        | 66/425 [01:25<03:37,  1.65it/s]#015 16%|        | 67/425 [01:25<03:35,  1.66it/s]#015 16%|        | 68/425 [01:26<03:40,  1.62it/s]#015 16%|        | 69/425 [01:27<03:40,  1.61it/s]#015 16%|        | 70/425 [01:27<03:38,  1.63it/s]#015 17%|        | 71/425 [01:28<03:36,  1.64it/s]#015 17%|        | 72/425 [01:28<03:33,  1.65it/s]#015 17%|        | 73/425 [01:29<03:32,  1.66it/s]#015 17%|        | 74/425 [01:30<03:32,  1.66it/s]#015 18%|        | 75/425 [01:30<03:30,  1.66it/s]#015 18%|        | 76/425 [01:31<03:30,  1.65it/s]#015 18%|        | 77/425 [01:31<03:28,  1.67it/s]#015 18%|        | 78/425 [01:32<03:27,  1.67it/s]#015 19%|        | 79/425 [01:33<03:26,  1.67it/s]#015 19%|        | 80/425 [01:33<03:26,  1.67it/s]#015 19%|        | 81/425 [01:34<03:27,  1.66it/s]#015 19%|        | 82/425 [01:34<03:32,  1.61it/s]#015 20%|        | 83/425 [01:35<03:29,  1.63it/s]#015 20%|        | 84/425 [01:36<03:30,  1.62it/s]#015 20%|        | 85/425 [01:36<03:26,  1.64it/s]#015 20%|        | 86/425 [01:37<03:32,  1.60it/s]#015 20%|        | 87/425 [01:38<03:28,  1.62it/s]#015 21%|        | 88/425 [01:38<03:25,  1.64it/s]#015 21%|        | 89/425 [01:39<03:23,  1.65it/s]#015 21%|        | 90/425 [01:39<03:21,  1.66it/s]#015 21%|       | 91/425 [01:40<03:21,  1.66it/s]#015 22%|       | 92/425 [01:41<03:20,  1.66it/s]#015 22%|       | 93/425 [01:41<03:25,  1.62it/s]#015 22%|       | 94/425 [01:42<03:27,  1.59it/s]#015 22%|       | 95/425 [01:42<03:25,  1.60it/s]#015 23%|       | 96/425 [01:43<03:22,  1.62it/s]#015 23%|       | 97/425 [01:44<03:20,  1.64it/s]#015 23%|       | 98/425 [01:44<03:19,  1.64it/s]#015 23%|       | 99/425 [01:45<03:17,  1.65it/s]#015 24%|       | 100/425 [01:45<03:17,  1.65it/s]#015 24%|       | 101/425 [01:46<03:14,  1.66it/s]#015 24%|       | 102/425 [01:47<03:13,  1.67it/s]#015 24%|       | 103/425 [01:47<03:13,  1.66it/s]#015 24%|       | 104/425 [01:48<03:13,  1.66it/s]#015 25%|       | 105/425 [01:48<03:12,  1.66it/s]#015 25%|       | 106/425 [01:49<03:12,  1.66it/s]#015 25%|       | 107/425 [01:50<03:11,  1.66it/s]#015 25%|       | 108/425 [01:50<03:10,  1.66it/s]#015 26%|       | 109/425 [01:51<03:10,  1.66it/s]#015 26%|       | 110/425 [01:51<03:11,  1.65it/s]#015 26%|       | 111/425 [01:52<03:12,  1.63it/s]#015 26%|       | 112/425 [01:53<03:11,  1.63it/s]#015 27%|       | 113/425 [01:53<03:12,  1.62it/s]#015 27%|       | 114/425 [01:54<03:11,  1.63it/s]#015 27%|       | 115/425 [01:55<03:14,  1.59it/s]#015 27%|       | 116/425 [01:55<03:14,  1.59it/s]#015 28%|       | 117/425 [01:56<03:13,  1.59it/s]#015 28%|       | 118/425 [01:57<03:16,  1.57it/s]#015 28%|       | 119/425 [01:57<03:17,  1.55it/s]#015 28%|       | 120/425 [01:58<03:13,  1.58it/s]#015 28%|       | 121/425 [01:58<03:09,  1.61it/s]#015 29%|       | 122/425 [01:59<03:05,  1.63it/s]#015 29%|       | 123/425 [02:00<03:04,  1.64it/s]#015 29%|       | 124/425 [02:00<03:03,  1.64it/s]#015 29%|       | 125/425 [02:01<03:02,  1.65it/s]#015 30%|       | 126/425 [02:01<03:00,  1.65it/s]#015 30%|       | 127/425 [02:02<02:59,  1.66it/s]#015 30%|       | 128/425 [02:03<02:59,  1.66it/s]#015 30%|       | 129/425 [02:03<02:59,  1.65it/s]#015 31%|       | 130/425 [02:04<02:58,  1.65it/s]#015 31%|       | 131/425 [02:04<03:02,  1.61it/s]#015 31%|       | 132/425 [02:05<03:05,  1.58it/s]#015 31%|      | 133/425 [02:06<03:02,  1.60it/s]#015 32%|      | 134/425 [02:06<03:05,  1.57it/s]#015 32%|      | 135/425 [02:07<03:01,  1.60it/s]#015 32%|      | 136/425 [02:08<02:58,  1.61it/s]#015 32%|      | 137/425 [02:08<02:58,  1.61it/s]#015 32%|      | 138/425 [02:09<02:56,  1.63it/s]#015 33%|      | 139/425 [02:09<02:55,  1.63it/s]#015 33%|      | 140/425 [02:10<02:57,  1.60it/s]#015 33%|      | 141/425 [02:11<02:55,  1.62it/s]#015 33%|      | 142/425 [02:11<02:56,  1.61it/s]#015 34%|      | 143/425 [02:12<02:53,  1.63it/s]#015 34%|      | 144/425 [02:13<02:51,  1.64it/s]#015 34%|      | 145/425 [02:13<02:50,  1.64it/s]#015 34%|      | 146/425 [02:14<02:49,  1.64it/s]#015 35%|      | 147/425 [02:14<02:49,  1.64it/s]#015 35%|      | 148/425 [02:15<02:54,  1.59it/s]#015 35%|      | 149/425 [02:16<02:51,  1.61it/s]#015 35%|      | 150/425 [02:16<02:50,  1.61it/s]#015 36%|      | 151/425 [02:17<02:48,  1.62it/s]#015 36%|      | 152/425 [02:17<02:46,  1.64it/s]#015 36%|      | 153/425 [02:18<02:45,  1.65it/s]#015 36%|      | 154/425 [02:19<02:45,  1.64it/s]#015 36%|      | 155/425 [02:19<02:43,  1.65it/s]#015 37%|      | 156/425 [02:20<02:42,  1.65it/s]#015 37%|      | 157/425 [02:20<02:42,  1.65it/s]#015 37%|      | 158/425 [02:21<02:42,  1.65it/s]#015 37%|      | 159/425 [02:22<02:40,  1.66it/s]#015 38%|      | 160/425 [02:22<02:39,  1.66it/s]#015 38%|      | 161/425 [02:23<02:39,  1.66it/s]#015 38%|      | 162/425 [02:23<02:38,  1.66it/s]#015 38%|      | 163/425 [02:24<02:38,  1.66it/s]#015 39%|      | 164/425 [02:25<02:37,  1.65it/s]#015 39%|      | 165/425 [02:25<02:38,  1.64it/s]#015 39%|      | 166/425 [02:26<02:37,  1.65it/s]#015 39%|      | 167/425 [02:27<02:36,  1.65it/s]#015 40%|      | 168/425 [02:27<02:35,  1.65it/s]#015 40%|      | 169/425 [02:28<02:36,  1.63it/s]#015 40%|      | 170/425 [02:28<02:35,  1.64it/s]#015 40%|      | 171/425 [02:29<02:34,  1.65it/s]#015 40%|      | 172/425 [02:30<02:33,  1.65it/s]#015 41%|      | 173/425 [02:30<02:33,  1.64it/s]#015 41%|      | 174/425 [02:31<02:34,  1.62it/s]#015 41%|      | 175/425 [02:31<02:33,  1.63it/s]#015 41%|     | 176/425 [02:32<02:33,  1.63it/s]#015 42%|     | 177/425 [02:33<02:31,  1.63it/s]#015 42%|     | 178/425 [02:33<02:30,  1.64it/s]#015 42%|     | 179/425 [02:34<02:30,  1.64it/s]#015 42%|     | 180/425 [02:35<02:33,  1.60it/s]#015 43%|     | 181/425 [02:35<02:31,  1.61it/s]#015 43%|     | 182/425 [02:36<02:29,  1.63it/s]#015 43%|     | 183/425 [02:36<02:27,  1.64it/s]#015 43%|     | 184/425 [02:37<02:26,  1.65it/s]#015 44%|     | 185/425 [02:38<02:24,  1.66it/s]#015 44%|     | 186/425 [02:38<02:24,  1.66it/s]#015 44%|     | 187/425 [02:39<02:23,  1.66it/s]#015 44%|     | 188/425 [02:39<02:23,  1.66it/s]#015 44%|     | 189/425 [02:40<02:26,  1.61it/s]#015 45%|     | 190/425 [02:41<02:26,  1.61it/s]#015 45%|     | 191/425 [02:41<02:24,  1.62it/s]#015 45%|     | 192/425 [02:42<02:26,  1.59it/s]#015 45%|     | 193/425 [02:42<02:24,  1.61it/s]#015 46%|     | 194/425 [02:43<02:22,  1.62it/s]#015 46%|     | 195/425 [02:44<02:21,  1.63it/s]#015 46%|     | 196/425 [02:44<02:20,  1.63it/s]#015 46%|     | 197/425 [02:45<02:19,  1.64it/s]#015 47%|     | 198/425 [02:46<02:17,  1.65it/s]#015 47%|     | 199/425 [02:46<02:21,  1.60it/s]#015 47%|     | 200/425 [02:47<02:19,  1.61it/s]#015 47%|     | 201/425 [02:47<02:17,  1.62it/s]#015 48%|     | 202/425 [02:48<02:18,  1.61it/s]#015 48%|     | 203/425 [02:49<02:17,  1.62it/s]#015 48%|     | 204/425 [02:49<02:15,  1.63it/s]#015 48%|     | 205/425 [02:50<02:15,  1.63it/s]#015 48%|     | 206/425 [02:50<02:13,  1.64it/s]#015 49%|     | 207/425 [02:51<02:16,  1.59it/s]#015 49%|     | 208/425 [02:52<02:14,  1.61it/s]#015 49%|     | 209/425 [02:52<02:12,  1.62it/s]#015 49%|     | 210/425 [02:53<02:12,  1.62it/s]#015 50%|     | 211/425 [02:54<02:11,  1.63it/s]#015 50%|     | 212/425 [02:54<02:10,  1.63it/s]#015 50%|     | 213/425 [02:55<02:11,  1.61it/s]#015 50%|     | 214/425 [02:55<02:12,  1.60it/s]#015 51%|     | 215/425 [02:56<02:11,  1.60it/s]#015 51%|     | 216/425 [02:57<02:11,  1.59it/s]#015 51%|     | 217/425 [02:57<02:09,  1.61it/s]#015 51%|    | 218/425 [02:58<02:07,  1.62it/s]#015 52%|    | 219/425 [02:59<02:07,  1.62it/s]#015 52%|    | 220/425 [02:59<02:07,  1.61it/s]#015 52%|    | 221/425 [03:00<02:05,  1.62it/s]#015 52%|    | 222/425 [03:00<02:04,  1.63it/s]#015 52%|    | 223/425 [03:01<02:03,  1.64it/s]#015 53%|    | 224/425 [03:02<02:05,  1.60it/s]#015 53%|    | 225/425 [03:02<02:03,  1.62it/s]#015 53%|    | 226/425 [03:03<02:02,  1.63it/s]#015 53%|    | 227/425 [03:03<02:01,  1.63it/s]#015 54%|    | 228/425 [03:04<02:00,  1.64it/s]#015 54%|    | 229/425 [03:05<01:59,  1.64it/s]#015 54%|    | 230/425 [03:05<01:58,  1.64it/s]#015 54%|    | 231/425 [03:06<01:57,  1.64it/s]#015 55%|    | 232/425 [03:06<01:57,  1.65it/s]#015 55%|    | 233/425 [03:07<01:56,  1.65it/s]#015 55%|    | 234/425 [03:08<01:57,  1.63it/s]#015 55%|    | 235/425 [03:08<01:56,  1.63it/s]#015 56%|    | 236/425 [03:09<01:55,  1.64it/s]#015 56%|    | 237/425 [03:10<01:54,  1.64it/s]#015 56%|    | 238/425 [03:10<01:53,  1.65it/s]#015 56%|    | 239/425 [03:11<01:52,  1.65it/s]#015 56%|    | 240/425 [03:11<01:52,  1.65it/s]#015 57%|    | 241/425 [03:12<01:50,  1.66it/s]#015 57%|    | 242/425 [03:13<01:50,  1.66it/s]#015 57%|    | 243/425 [03:13<01:50,  1.64it/s]#015 57%|    | 244/425 [03:14<01:50,  1.64it/s]#015 58%|    | 245/425 [03:14<01:49,  1.65it/s]#015 58%|    | 246/425 [03:15<01:48,  1.65it/s]#015 58%|    | 247/425 [03:16<01:47,  1.65it/s]#015 58%|    | 248/425 [03:16<01:49,  1.61it/s]#015 59%|    | 249/425 [03:17<01:48,  1.63it/s]#015 59%|    | 250/425 [03:17<01:46,  1.64it/s]#015 59%|    | 251/425 [03:18<01:45,  1.65it/s]#015 59%|    | 252/425 [03:19<01:45,  1.64it/s]#015 60%|    | 253/425 [03:19<01:45,  1.64it/s]#015 60%|    | 254/425 [03:20<01:44,  1.64it/s]#015 60%|    | 255/425 [03:20<01:43,  1.65it/s]#015 60%|    | 256/425 [03:21<01:42,  1.66it/s]#015 60%|    | 257/425 [03:22<01:41,  1.66it/s]#015 61%|    | 258/425 [03:22<01:40,  1.66it/s]#015 61%|    | 259/425 [03:23<01:39,  1.66it/s]#015 61%|    | 260/425 [03:23<01:39,  1.66it/s]#015 61%|   | 261/425 [03:24<01:38,  1.66it/s]#015 62%|   | 262/425 [03:25<01:38,  1.65it/s]#015 62%|   | 263/425 [03:25<01:38,  1.64it/s]#015 62%|   | 264/425 [03:26<01:38,  1.64it/s]#015 62%|   | 265/425 [03:27<01:37,  1.65it/s]#015 63%|   | 266/425 [03:27<01:36,  1.65it/s]#015 63%|   | 267/425 [03:28<01:35,  1.66it/s]#015 63%|   | 268/425 [03:28<01:35,  1.65it/s]#015 63%|   | 269/425 [03:29<01:34,  1.65it/s]#015 64%|   | 270/425 [03:30<01:33,  1.65it/s]#015 64%|   | 271/425 [03:30<01:33,  1.65it/s]#015 64%|   | 272/425 [03:31<01:32,  1.65it/s]#015 64%|   | 273/425 [03:31<01:32,  1.65it/s]#015 64%|   | 274/425 [03:32<01:31,  1.65it/s]#015 65%|   | 275/425 [03:33<01:30,  1.65it/s]#015 65%|   | 276/425 [03:33<01:30,  1.65it/s]#015 65%|   | 277/425 [03:34<01:29,  1.66it/s]#015 65%|   | 278/425 [03:34<01:29,  1.64it/s]#015 66%|   | 279/425 [03:35<01:28,  1.65it/s]#015 66%|   | 280/425 [03:36<01:27,  1.66it/s]#015 66%|   | 281/425 [03:36<01:26,  1.66it/s]#015 66%|   | 282/425 [03:37<01:26,  1.66it/s]#015 67%|   | 283/425 [03:37<01:25,  1.66it/s]#015 67%|   | 284/425 [03:38<01:27,  1.61it/s]#015 67%|   | 285/425 [03:39<01:26,  1.62it/s]#015 67%|   | 286/425 [03:39<01:25,  1.63it/s]\u001b[0m\n",
      "\u001b[34m#015 68%|   | 287/425 [03:40<01:24,  1.64it/s]#015 68%|   | 288/425 [03:41<01:24,  1.63it/s]#015 68%|   | 289/425 [03:41<01:23,  1.63it/s]#015 68%|   | 290/425 [03:42<01:22,  1.64it/s]#015 68%|   | 291/425 [03:42<01:21,  1.65it/s]#015 69%|   | 292/425 [03:43<01:20,  1.65it/s]#015 69%|   | 293/425 [03:44<01:20,  1.64it/s]#015 69%|   | 294/425 [03:44<01:19,  1.66it/s]#015 69%|   | 295/425 [03:45<01:18,  1.65it/s]#015 70%|   | 296/425 [03:45<01:17,  1.66it/s]#015 70%|   | 297/425 [03:46<01:16,  1.66it/s]#015 70%|   | 298/425 [03:47<01:16,  1.65it/s]#015 70%|   | 299/425 [03:47<01:16,  1.66it/s]#015 71%|   | 300/425 [03:48<01:15,  1.66it/s]#015 71%|   | 301/425 [03:48<01:14,  1.65it/s]#015 71%|   | 302/425 [03:49<01:14,  1.65it/s]#015 71%|  | 303/425 [03:50<01:14,  1.63it/s]#015 72%|  | 304/425 [03:50<01:13,  1.64it/s]#015 72%|  | 305/425 [03:51<01:12,  1.65it/s]#015 72%|  | 306/425 [03:51<01:11,  1.66it/s]#015 72%|  | 307/425 [03:52<01:10,  1.66it/s]#015 72%|  | 308/425 [03:53<01:10,  1.66it/s]#015 73%|  | 309/425 [03:53<01:10,  1.65it/s]#015 73%|  | 310/425 [03:54<01:09,  1.65it/s]#015 73%|  | 311/425 [03:54<01:09,  1.63it/s]#015 73%|  | 312/425 [03:55<01:08,  1.64it/s]#015 74%|  | 313/425 [03:56<01:09,  1.62it/s]#015 74%|  | 314/425 [03:56<01:09,  1.60it/s]#015 74%|  | 315/425 [03:57<01:09,  1.58it/s]#015 74%|  | 316/425 [03:58<01:08,  1.60it/s]#015 75%|  | 317/425 [03:58<01:07,  1.61it/s]#015 75%|  | 318/425 [03:59<01:06,  1.61it/s]#015 75%|  | 319/425 [03:59<01:05,  1.62it/s]#015 75%|  | 320/425 [04:00<01:04,  1.64it/s]#015 76%|  | 321/425 [04:01<01:03,  1.65it/s]#015 76%|  | 322/425 [04:01<01:04,  1.60it/s]#015 76%|  | 323/425 [04:02<01:03,  1.61it/s]#015 76%|  | 324/425 [04:03<01:02,  1.62it/s]#015 76%|  | 325/425 [04:03<01:01,  1.64it/s]#015 77%|  | 326/425 [04:04<01:00,  1.64it/s]#015 77%|  | 327/425 [04:04<00:59,  1.65it/s]#015 77%|  | 328/425 [04:05<00:58,  1.65it/s]#015 77%|  | 329/425 [04:06<00:58,  1.65it/s]#015 78%|  | 330/425 [04:06<00:57,  1.66it/s]#015 78%|  | 331/425 [04:07<00:56,  1.67it/s]#015 78%|  | 332/425 [04:07<00:57,  1.63it/s]#015 78%|  | 333/425 [04:08<00:56,  1.63it/s]#015 79%|  | 334/425 [04:09<00:55,  1.64it/s]#015 79%|  | 335/425 [04:09<00:54,  1.65it/s]#015 79%|  | 336/425 [04:10<00:53,  1.66it/s]#015 79%|  | 337/425 [04:10<00:53,  1.65it/s]#015 80%|  | 338/425 [04:11<00:53,  1.64it/s]#015 80%|  | 339/425 [04:12<00:52,  1.65it/s]#015 80%|  | 340/425 [04:12<00:51,  1.65it/s]#015 80%|  | 341/425 [04:13<00:50,  1.65it/s]#015 80%|  | 342/425 [04:13<00:52,  1.59it/s]#015 81%|  | 343/425 [04:14<00:52,  1.57it/s]#015 81%|  | 344/425 [04:15<00:50,  1.60it/s]#015 81%|  | 345/425 [04:15<00:49,  1.61it/s]#015 81%| | 346/425 [04:16<00:48,  1.62it/s]#015 82%| | 347/425 [04:17<00:47,  1.64it/s]#015 82%| | 348/425 [04:17<00:46,  1.65it/s]#015 82%| | 349/425 [04:18<00:46,  1.63it/s]#015 82%| | 350/425 [04:18<00:45,  1.64it/s]#015 83%| | 351/425 [04:19<00:45,  1.63it/s]#015 83%| | 352/425 [04:20<00:44,  1.64it/s]#015 83%| | 353/425 [04:20<00:43,  1.65it/s]#015 83%| | 354/425 [04:21<00:43,  1.65it/s]#015 84%| | 355/425 [04:21<00:42,  1.66it/s]#015 84%| | 356/425 [04:22<00:41,  1.64it/s]#015 84%| | 357/425 [04:23<00:41,  1.65it/s]#015 84%| | 358/425 [04:23<00:40,  1.65it/s]#015 84%| | 359/425 [04:24<00:39,  1.66it/s]#015 85%| | 360/425 [04:24<00:39,  1.65it/s]#015 85%| | 361/425 [04:25<00:38,  1.65it/s]#015 85%| | 362/425 [04:26<00:38,  1.65it/s]#015 85%| | 363/425 [04:26<00:37,  1.65it/s]#015 86%| | 364/425 [04:27<00:36,  1.65it/s]#015 86%| | 365/425 [04:27<00:36,  1.65it/s]#015 86%| | 366/425 [04:28<00:36,  1.64it/s]#015 86%| | 367/425 [04:29<00:35,  1.62it/s]#015 87%| | 368/425 [04:29<00:34,  1.63it/s]#015 87%| | 369/425 [04:30<00:34,  1.64it/s]#015 87%| | 370/425 [04:31<00:33,  1.64it/s]#015 87%| | 371/425 [04:31<00:33,  1.62it/s]#015 88%| | 372/425 [04:32<00:32,  1.63it/s]#015 88%| | 373/425 [04:32<00:31,  1.64it/s]#015 88%| | 374/425 [04:33<00:30,  1.65it/s]#015 88%| | 375/425 [04:34<00:30,  1.65it/s]#015 88%| | 376/425 [04:34<00:30,  1.63it/s]#015 89%| | 377/425 [04:35<00:30,  1.59it/s]#015 89%| | 378/425 [04:36<00:29,  1.60it/s]#015 89%| | 379/425 [04:36<00:28,  1.61it/s]#015 89%| | 380/425 [04:37<00:27,  1.61it/s]#015 90%| | 381/425 [04:37<00:27,  1.59it/s]#015 90%| | 382/425 [04:38<00:26,  1.61it/s]#015 90%| | 383/425 [04:39<00:25,  1.62it/s]#015 90%| | 384/425 [04:39<00:25,  1.63it/s]#015 91%| | 385/425 [04:40<00:24,  1.63it/s]#015 91%| | 386/425 [04:40<00:23,  1.64it/s]#015 91%| | 387/425 [04:41<00:23,  1.65it/s]#015 91%|| 388/425 [04:42<00:22,  1.65it/s]#015 92%|| 389/425 [04:42<00:21,  1.66it/s]#015 92%|| 390/425 [04:43<00:21,  1.66it/s]#015 92%|| 391/425 [04:43<00:20,  1.66it/s]#015 92%|| 392/425 [04:44<00:19,  1.66it/s]#015 92%|| 393/425 [04:45<00:19,  1.66it/s]#015 93%|| 394/425 [04:45<00:18,  1.65it/s]#015 93%|| 395/425 [04:46<00:18,  1.65it/s]#015 93%|| 396/425 [04:46<00:17,  1.65it/s]#015 93%|| 397/425 [04:47<00:16,  1.66it/s]#015 94%|| 398/425 [04:48<00:16,  1.66it/s]#015 94%|| 399/425 [04:48<00:15,  1.63it/s]#015 94%|| 400/425 [04:49<00:15,  1.63it/s]#015 94%|| 401/425 [04:50<00:14,  1.64it/s]#015 95%|| 402/425 [04:50<00:14,  1.63it/s]#015 95%|| 403/425 [04:51<00:13,  1.64it/s]#015 95%|| 404/425 [04:51<00:12,  1.63it/s]#015 95%|| 405/425 [04:52<00:12,  1.64it/s]#015 96%|| 406/425 [04:53<00:11,  1.64it/s]#015 96%|| 407/425 [04:53<00:10,  1.64it/s]#015 96%|| 408/425 [04:54<00:10,  1.64it/s]#015 96%|| 409/425 [04:54<00:09,  1.63it/s]#015 96%|| 410/425 [04:55<00:09,  1.63it/s]#015 97%|| 411/425 [04:56<00:08,  1.62it/s]#015 97%|| 412/425 [04:56<00:08,  1.60it/s]#015 97%|| 413/425 [04:57<00:07,  1.58it/s]#015 97%|| 414/425 [04:58<00:07,  1.54it/s]#015 98%|| 415/425 [04:58<00:06,  1.56it/s]#015 98%|| 416/425 [04:59<00:05,  1.59it/s]#015 98%|| 417/425 [04:59<00:04,  1.61it/s]#015 98%|| 418/425 [05:00<00:04,  1.62it/s]#015 99%|| 419/425 [05:01<00:03,  1.62it/s]#015 99%|| 420/425 [05:01<00:03,  1.64it/s]#015 99%|| 421/425 [05:02<00:02,  1.64it/s]#015 99%|| 422/425 [05:03<00:01,  1.63it/s]#015100%|| 423/425 [05:03<00:01,  1.64it/s]#015100%|| 424/425 [05:04<00:00,  1.65it/s]#015100%|| 425/425 [05:04<00:00,  1.88it/s]\u001b[0m\n",
      "\u001b[34m2021-08-23 21:47:16,320 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/71 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  3%|         | 2/71 [00:00<00:15,  4.56it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|         | 3/71 [00:00<00:19,  3.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  6%|         | 4/71 [00:01<00:22,  2.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|         | 5/71 [00:01<00:24,  2.74it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|         | 6/71 [00:02<00:25,  2.57it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 10%|         | 7/71 [00:02<00:25,  2.48it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|        | 8/71 [00:03<00:25,  2.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|        | 9/71 [00:03<00:26,  2.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 14%|        | 10/71 [00:03<00:25,  2.36it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|        | 11/71 [00:04<00:25,  2.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|        | 12/71 [00:04<00:25,  2.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|        | 13/71 [00:05<00:25,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|        | 14/71 [00:05<00:24,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 21%|        | 15/71 [00:06<00:24,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 23%|       | 16/71 [00:06<00:23,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|       | 17/71 [00:07<00:23,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|       | 18/71 [00:07<00:23,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|       | 19/71 [00:07<00:22,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|       | 20/71 [00:08<00:22,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 30%|       | 21/71 [00:08<00:21,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|       | 22/71 [00:09<00:21,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|      | 23/71 [00:09<00:21,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 34%|      | 24/71 [00:10<00:20,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|      | 25/71 [00:10<00:20,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 37%|      | 26/71 [00:10<00:19,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|      | 27/71 [00:11<00:19,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 39%|      | 28/71 [00:11<00:18,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 41%|      | 29/71 [00:12<00:18,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|     | 30/71 [00:12<00:17,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|     | 31/71 [00:13<00:17,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|     | 32/71 [00:13<00:17,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 46%|     | 33/71 [00:13<00:16,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|     | 34/71 [00:14<00:16,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|     | 35/71 [00:14<00:15,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|     | 36/71 [00:15<00:15,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|    | 37/71 [00:15<00:14,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 54%|    | 38/71 [00:16<00:14,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|    | 39/71 [00:16<00:13,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|    | 40/71 [00:17<00:13,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|    | 41/71 [00:17<00:13,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 59%|    | 42/71 [00:17<00:12,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 61%|    | 43/71 [00:18<00:12,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|   | 44/71 [00:18<00:11,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 63%|   | 45/71 [00:19<00:11,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|   | 46/71 [00:19<00:10,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 66%|   | 47/71 [00:20<00:10,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|   | 48/71 [00:20<00:09,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|   | 49/71 [00:20<00:09,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 70%|   | 50/71 [00:21<00:09,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|  | 51/71 [00:21<00:08,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|  | 52/71 [00:22<00:08,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|  | 53/71 [00:22<00:07,  2.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|  | 54/71 [00:23<00:07,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 77%|  | 55/71 [00:23<00:07,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 79%|  | 56/71 [00:24<00:06,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|  | 57/71 [00:24<00:06,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%| | 58/71 [00:24<00:05,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%| | 59/71 [00:25<00:05,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%| | 60/71 [00:25<00:04,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 86%| | 61/71 [00:26<00:04,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%| | 62/71 [00:26<00:03,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%| | 63/71 [00:27<00:03,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 90%| | 64/71 [00:27<00:03,  2.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|| 65/71 [00:27<00:02,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|| 66/71 [00:28<00:02,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 94%|| 67/71 [00:28<00:01,  2.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|| 68/71 [00:29<00:01,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 97%|| 69/71 [00:29<00:00,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 99%|| 70/71 [00:30<00:00,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|| 71/71 [00:30<00:00,  2.47it/s]#033[A/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\u001b[0m\n",
      "\u001b[34m#015                                                 #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015100%|| 425/425 [05:35<00:00,  1.88it/s]\u001b[0m\n",
      "\u001b[34m#015100%|| 71/71 [00:30<00:00,  2.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A#015                                                 #015#015100%|| 425/425 [05:35<00:00,  1.88it/s]#015100%|| 425/425 [05:35<00:00,  1.27it/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/71 [00:00<?, ?it/s]#015  3%|         | 2/71 [00:00<00:15,  4.56it/s]#015  4%|         | 3/71 [00:00<00:19,  3.49it/s]#015  6%|         | 4/71 [00:01<00:22,  3.01it/s]#015  7%|         | 5/71 [00:01<00:24,  2.73it/s]#015  8%|         | 6/71 [00:02<00:25,  2.59it/s]#015 10%|         | 7/71 [00:02<00:25,  2.50it/s]#015 11%|        | 8/71 [00:03<00:25,  2.44it/s]#015 13%|        | 9/71 [00:03<00:25,  2.41it/s]#015 14%|        | 10/71 [00:03<00:25,  2.36it/s]#015 15%|        | 11/71 [00:04<00:25,  2.34it/s]#015 17%|        | 12/71 [00:04<00:25,  2.32it/s]#015 18%|        | 13/71 [00:05<00:25,  2.30it/s]#015 20%|        | 14/71 [00:05<00:24,  2.30it/s]#015 21%|        | 15/71 [00:06<00:24,  2.30it/s]#015 23%|       | 16/71 [00:06<00:23,  2.29it/s]#015 24%|       | 17/71 [00:07<00:23,  2.29it/s]#015 25%|       | 18/71 [00:07<00:23,  2.28it/s]#015 27%|       | 19/71 [00:07<00:22,  2.30it/s]#015 28%|       | 20/71 [00:08<00:22,  2.30it/s]#015 30%|       | 21/71 [00:08<00:21,  2.29it/s]#015 31%|       | 22/71 [00:09<00:21,  2.29it/s]#015 32%|      | 23/71 [00:09<00:20,  2.30it/s]#015 34%|      | 24/71 [00:10<00:20,  2.27it/s]#015 35%|      | 25/71 [00:10<00:20,  2.27it/s]#015 37%|      | 26/71 [00:10<00:19,  2.27it/s]#015 38%|      | 27/71 [00:11<00:19,  2.28it/s]#015 39%|      | 28/71 [00:11<00:18,  2.28it/s]#015 41%|      | 29/71 [00:12<00:18,  2.28it/s]#015 42%|     | 30/71 [00:12<00:17,  2.28it/s]#015 44%|     | 31/71 [00:13<00:17,  2.29it/s]#015 45%|     | 32/71 [00:13<00:17,  2.27it/s]#015 46%|     | 33/71 [00:14<00:16,  2.29it/s]#015 48%|     | 34/71 [00:14<00:16,  2.29it/s]#015 49%|     | 35/71 [00:14<00:15,  2.28it/s]#015 51%|     | 36/71 [00:15<00:15,  2.29it/s]#015 52%|    | 37/71 [00:15<00:14,  2.30it/s]#015 54%|    | 38/71 [00:16<00:14,  2.31it/s]#015 55%|    | 39/71 [00:16<00:13,  2.30it/s]#015 56%|    | 40/71 [00:17<00:13,  2.30it/s]#015 58%|    | 41/71 [00:17<00:13,  2.27it/s]#015 59%|    | 42/71 [00:17<00:12,  2.27it/s]#015 61%|    | 43/71 [00:18<00:12,  2.28it/s]#015 62%|   | 44/71 [00:18<00:11,  2.28it/s]#015 63%|   | 45/71 [00:19<00:11,  2.27it/s]#015 65%|   | 46/71 [00:19<00:10,  2.28it/s]#015 66%|   | 47/71 [00:20<00:10,  2.27it/s]#015 68%|   | 48/71 [00:20<00:10,  2.22it/s]#015 69%|   | 49/71 [00:21<00:09,  2.22it/s]#015 70%|   | 50/71 [00:21<00:09,  2.23it/s]#015 72%|  | 51/71 [00:21<00:08,  2.23it/s]#015 73%|  | 52/71 [00:22<00:08,  2.24it/s]#015 75%|  | 53/71 [00:22<00:08,  2.25it/s]#015 76%|  | 54/71 [00:23<00:07,  2.27it/s]#015 77%|  | 55/71 [00:23<00:07,  2.28it/s]#015 79%|  | 56/71 [00:24<00:06,  2.29it/s]#015 80%|  | 57/71 [00:24<00:06,  2.30it/s]#015 82%| | 58/71 [00:25<00:05,  2.30it/s]#015 83%| | 59/71 [00:25<00:05,  2.30it/s]#015 85%| | 60/71 [00:25<00:04,  2.30it/s]#015 86%| | 61/71 [00:26<00:04,  2.30it/s]#015 87%| | 62/71 [00:26<00:03,  2.29it/s]#015 89%| | 63/71 [00:27<00:03,  2.30it/s]#015 90%| | 64/71 [00:27<00:03,  2.29it/s]#015 92%|| 65/71 [00:28<00:02,  2.29it/s]#015 93%|| 66/71 [00:28<00:02,  2.30it/s]#015 94%|| 67/71 [00:28<00:01,  2.29it/s]#015 96%|| 68/71 [00:29<00:01,  2.30it/s]#015 97%|| 69/71 [00:29<00:00,  2.31it/s]#015 99%|| 70/71 [00:30<00:00,  2.29it/s]#015100%|| 71/71 [00:30<00:00,  2.45it/s]/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\u001b[0m\n",
      "\u001b[34m#015100%|| 71/71 [00:30<00:00,  2.32it/s]\n",
      "\u001b[0m\n",
      "\n",
      "2021-08-23 21:47:36 Uploading - Uploading generated training modelLowGPUUtilization: IssuesFound\n",
      "ProfilerReport: InProgress\n",
      "\n",
      "2021-08-23 21:48:04 Completed - Training job completed\n",
      "Training seconds: 627\n",
      "Billable seconds: 627\n"
     ]
    }
   ],
   "source": [
    "data = {'train': f\"s3://{bucket}/{prefix}/data/train.csv\",\n",
    "        'test': f\"s3://{bucket}/{prefix}/data/validate.csv\"\n",
    "       }\n",
    "\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captured metrics can be accessed as a Pandas dataframe\n",
    "training_job_name = huggingface_estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "\n",
    "df = TrainingJobAnalytics(training_job_name=training_job_name).dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Profiling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the training is still in progress you can visualize the performance data in SageMaker Studio or in the notebook. Debugger provides utilities to plot system metrics in form of timeline charts or heatmaps. Checkout out the notebook profiling_interactive_analysis.ipynb for more details. In the following code cell we plot the total CPU and GPU utilization as timeseries charts. To visualize other metrics such as I/O, memory, network you simply need to extend the list passed to select_dimension and select_events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Debugger Profling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profiling report rule will create an html report profiler-report.html with a summary of builtin rules and recommenades of next steps. You can find this report in your S3 bucket.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_output_path = huggingface_estimator.output_path + huggingface_estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"You will find the profiler report in {rule_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.download_data(path = '.',\n",
    "                               bucket = bucket,\n",
    "                               key_prefix = f'{prefix}/training_jobs/{huggingface_estimator.latest_training_job.job_name}/rule-output/ProfilerReport/profiler-output/profiler-report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about how to download and open the Debugger profiling report, see [SageMaker Debugger Profiling Report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html) in the SageMaker developer guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f'huggingface-finetune-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=huggingface_estimator.model_data, # S3 path to your trained sagemaker model\n",
    "    role=role, # IAM role with permissions to create an Endpoint\n",
    "    transformers_version='4.6',\n",
    "    pytorch_version='1.7',\n",
    "    py_version='py36'\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name = endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "test_small = test[:100] # Predicting only on 100 rows, change this to predict on a larger number of rows\n",
    "\n",
    "for idx, row in test_small.iterrows():\n",
    "    payload = {\"inputs\": row['text']}\n",
    "    pred = predictor.predict(payload)[0]\n",
    "    \n",
    "    # rename label to prediction\n",
    "    pred['prediction'] = pred.pop('label')\n",
    "    # convert prediction value to int\n",
    "    pred['prediction'] = int(pred['prediction'].replace('LABEL_', ''))\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_small['prediction'] = pred_list\n",
    "df_test = pd.concat([test_small.drop(['prediction'], axis=1), test_small['prediction'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_test['label'], df_test['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the endpoint with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = boto3.client('sagemaker')\n",
    "# endpoint = client.list_endpoints()['Endpoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"inputs\": [test['text'].iloc[0]]}\n",
    "\n",
    "predictor = HuggingFacePredictor(endpoint_name=endpoint_name,\n",
    "                                sagemaker_session=sagemaker_session\n",
    "                                )\n",
    "result = predictor.predict(data=payload)[0]\n",
    "print(f\"Predicted \\033[1m{result['label']}\\033[0m with score of \\033[1m{round(result['score'], 2)}\\033[0m. Real label is \\033[1m{test['label'].iloc[0]}\\033[0m. Full sentence:\\n\\n{test['text'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: invoke the endpoint with boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "payload = {\"inputs\": [test['text'].iloc[0]]}\n",
    "user_encode_data = json.dumps(payload).encode('utf-8')\n",
    "\n",
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                          Body=user_encode_data,\n",
    "                          ContentType='application/json'\n",
    "                         )\n",
    "\n",
    "result = json.loads(response['Body'].read())[0]\n",
    "print(f\"Predicted \\033[1m{result['label']}\\033[0m with score of \\033[1m{round(result['score'], 2)}\\033[0m. Real label is \\033[1m{test['label'].iloc[0]}\\033[0m. Full sentence:\\n\\n{test['text'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "\n",
    "Make sure you delete the SageMaker endpoints to avoid unnecessary costs:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
