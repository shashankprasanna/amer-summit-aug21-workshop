[
{
	"uri": "/1_setup/login_aws_account.html",
	"title": "1.1 Login to your temporary workshop AWS Account",
	"tags": [],
	"description": "",
	"content": " Get your temporary AWS account Click on the link at the bottom of the browser as show below.\nClick on Accept Terms \u0026amp; Login Click on Email One-Time OTP (Allow for up to 2 mins to receive the passcode) Provide your email address Enter your OTP code Click on AWS Console Click on Open AWS Console In the AWS Console click on Amazon SageMaker Click on Amazon SageMaker Studio and then click on Open Studio You should now have Amazon SageMaker Studio interface open on your browser "
},
{
	"uri": "/2_build-train-tune-deploy/prepare_dataset.html",
	"title": "2.1 Prepare your dataset and upload it to Amazon S3",
	"tags": [],
	"description": "",
	"content": " Open the following notebook to follow along Notebook: 1_prepare_dataset.ipynb\nWatch the livestream to follow along with the presenter\n Let\u0026rsquo;s start by importing necessary packages. We\u0026rsquo;ll use sagemaker and boto3 to access Amazon S3 and numpy and pandas to pre-process the dataset\nimport sagemaker import boto3 import pandas as pd import numpy as np Create a sagemaker session and get access to the current role\nsess = boto3.Session() sagemaker_session = sagemaker.Session() role = sagemaker.get_execution_role() We\u0026rsquo;ll use the default S3 bucket to save dataset, training jobs and artifacts. You can use the sagemaker session to get the path to the default bucket. Use a custom prefix to save all the workshop artifacts.\nbucket = sagemaker_session.default_bucket() prefix = \u0026#34;sagemaker_huggingface_workshop\u0026#34; Print the role, bucket and region\nprint(f\u0026#34;sagemaker role arn: {role}\u0026#34;) print(f\u0026#34;sagemaker bucket: {sagemaker_session.default_bucket()}\u0026#34;) print(f\u0026#34;sagemaker session region: {sagemaker_session.boto_region_name}\u0026#34;) Preparing the dataset Women\u0026rsquo;s E-Commerce Clothing Reviews with 23,000 Customer Reviews and Ratings https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews\nLoad dataset and extract only the reviews and ratings\ndf = pd.read_csv(\u0026#39;./data/Womens Clothing E-Commerce Reviews.csv\u0026#39;) df = df[[\u0026#39;Review Text\u0026#39;,\t\u0026#39;Rating\u0026#39;]] df.columns = [\u0026#39;text\u0026#39;, \u0026#39;label\u0026#39;] df[\u0026#39;label\u0026#39;] = df[\u0026#39;label\u0026#39;] - 1 df = df.dropna()import matplotlib.pyplot as plt %matplotlib inline unique, counts = np.unique(df[\u0026#39;label\u0026#39;], return_counts=True) plt.bar(unique, counts) plt.title(\u0026#39;Class Frequency\u0026#39;) plt.xlabel(\u0026#39;Class\u0026#39;) plt.ylabel(\u0026#39;Frequency\u0026#39;) plt.show() Create a train, validate and test set\ntrain, validate, test = \\ np.split(df.sample(frac=1, random_state=42), [int(.6*len(df)), int(.8*len(df))]) train.shape, validate.shape, test.shapetrain.head(10) Create separate files for train, validate and test\ntrain.to_csv( \u0026#39;./data/train.csv\u0026#39; , index=False) validate.to_csv(\u0026#39;./data/validate.csv\u0026#39;, index=False) test.to_csv( \u0026#39;./data/test.csv\u0026#39; , index=False) Upload all 3 files to the default bucket in Amazon S3\ndataset_path = sagemaker_session.upload_data(path=\u0026#39;data\u0026#39;, key_prefix=f\u0026#39;{prefix}/data\u0026#39;) print(f\u0026#39;Dataset location: {dataset_path}\u0026#39;)"
},
{
	"uri": "/appendix/docs.html",
	"title": "Documentation resources",
	"tags": [],
	"description": "",
	"content": " 1. SageMaker SDK API guide https://sagemaker.readthedocs.io/en/stable/\n2. SageMaker Sample Notebooks on GitHub https://github.com/awslabs/amazon-sagemaker-examples\n3. SageMaker Developer Guide https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html\n4. SageMaker API Reference https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_Operations_Amazon_SageMaker_Service.html\n"
},
{
	"uri": "/",
	"title": "Welcome to Solving natural language processing problems with Amazon SageMaker Workshop at AMER Summit",
	"tags": [],
	"description": "",
	"content": " Solving natural language processing problems with Amazon SageMaker Workshop Presenters    Shashank Prasanna, Sr. Developer Advocate, AI/ML Amir Imani,\nAI/ML Specialist SA     Twitter: @shshnkp\nlinkedin.com/in/shashankprasanna\nmedium.com/@shashankprasanna Twitter: @amirhos_imani\nlinkedin.com/in/aimani\n    Workshop Overview Workshop duration: 2 hours\nAbstract: Recent advances in machine learning (ML) have enabled significant breakthroughs in the field of natural language processing (NLP). With state-of-the-art ML models, you can perform a range of NLP tasks such as sentiment analysis, text summarization, and more. In this 2-hour, fully remote technical workshop, AWS experts walk you through step-by-step instructions on how to use Amazon SageMaker and Hugging Face to build, train, tune, and deploy ML models at scale.\nAt the end of this workshop you will be able to:\n Easily fine-tune or train NLP models from scratch on text data using Amazon SageMaker and HuggingFace library integration.\n Accelerate ML development and optimize training cost by leveraging Amazon SageMaker Studio notebooks, fully-managed training instances and managed spot training\n Apply the steps learnt in the workshop on your own datasets for NLP usecases such as text classification, text summarization Q\u0026amp;A, and others\n  Agenda    Topics Duration     Workshop overview and setup 10 mins   Getting started 15 mins   Problem overview and dataset preparation 15 mins   Train and fine-tune NLP models with SageMaker and HuggingFace 60 mins   Wrap Up 20 mins    "
},
{
	"uri": "/0_introduction.html",
	"title": "Workshop Interface Overview",
	"tags": [],
	"description": "",
	"content": "Watch this short video at anytime to familiarize yourself with the workshop interface.   "
},
{
	"uri": "/1_setup.html",
	"title": "1. Getting started",
	"tags": [],
	"description": "",
	"content": "For this workshop you\u0026rsquo;ll get access to a temporary AWS Account already pre-configured with Amazon SageMaker Studio. Follow the steps in this section to login to your AWS Account and download the workshop material.\n"
},
{
	"uri": "/1_setup/download_workshop_content.html",
	"title": "1.2 Download workshop content",
	"tags": [],
	"description": "",
	"content": " Watch the livestream to follow along with the presenter\n Open a new terminal window Clone the workshop content In the terminal paste the following command to clone the workshop content repo:\ngit clone https://github.com/shashankprasanna/amer-summit-aug21-workshop.git  Double click on the amer-summit-aug21-workshop folder Double click on notebooks folder Double click on the the first notebook Choose the Python 3 (Data Science kernel) and hit select "
},
{
	"uri": "/2_build-train-tune-deploy/how-it-works.html",
	"title": "2.2 How Amazon SageMaker and HuggingFace work together",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/2_build-train-tune-deploy/finetune_huggingface.html",
	"title": "2.3 Train and fine-tune NLP models with SageMaker and HuggingFace library",
	"tags": [],
	"description": "",
	"content": " Open the following notebook to follow along Notebook: 2_finetune_deploy_huggingface\nWatch the livestream to follow along with the presenter\n Finetuning HuggingFace models with Amazon SageMaker\nInstall or upgrade sagemaker sdk and sagemaker debugger sdk\n!pip install -Uq sagemaker smdebug # Ignore warnings related to pipimport boto3 import time import numpy as np import pandas as pd import json from datetime import datetime as dt from IPython.display import FileLink import sagemaker from sagemaker import TrainingJobAnalytics from sagemaker.debugger import Rule, ProfilerRule, rule_configs from sagemaker.debugger import ProfilerConfig, FrameworkProfile, DebuggerHookConfig from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts from sagemaker.huggingface import HuggingFace, HuggingFaceModel, HuggingFacePredictor from sklearn.metrics import classification_report# permissions sess = boto3.Session() sagemaker_session = sagemaker.Session() role = sagemaker.get_execution_role() bucket = sagemaker_session.default_bucket() prefix = \u0026#34;sagemaker_huggingface_workshop\u0026#34; print(f\u0026#34;sagemaker role arn: {role}\u0026#34;) print(f\u0026#34;sagemaker bucket: {sagemaker_session.default_bucket()}\u0026#34;) print(f\u0026#34;sagemaker session region: {sagemaker_session.boto_region_name}\u0026#34;) Prepare a HuggingFace Transformers fine-tuning script. The training script that performs fine tuning is located here: src/train.py Navigate to the source code location and open the train.py file. You can also go through it\u0026rsquo;s contents by executing the cell below.\n!pygmentize src/train.py Create a HuggingFace Estimator hyperparameters, which are passed into the training job hyperparameters={\u0026#39;epochs\u0026#39;: 1, \u0026#39;train_batch_size\u0026#39;: 32, \u0026#39;model_name\u0026#39;:\u0026#39;distilbert-base-uncased\u0026#39;, } List of supported models: https://huggingface.co/transformers/pretrained_models.html\nmetric_definitions=[ {\u0026#39;Name\u0026#39;: \u0026#39;eval_loss\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;eval_loss\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}, {\u0026#39;Name\u0026#39;: \u0026#39;eval_accuracy\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;eval_accuracy\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}, {\u0026#39;Name\u0026#39;: \u0026#39;eval_f1\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;eval_f1\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}, {\u0026#39;Name\u0026#39;: \u0026#39;eval_precision\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;eval_precision\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}, {\u0026#39;Name\u0026#39;: \u0026#39;eval_recall\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;eval_recall\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}, {\u0026#39;Name\u0026#39;: \u0026#39;eval_runtime\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;eval_runtime\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}, {\u0026#39;Name\u0026#39;: \u0026#39;eval_samples_per_second\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;eval_samples_per_second\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}, {\u0026#39;Name\u0026#39;: \u0026#39;epoch\u0026#39;, \u0026#39;Regex\u0026#39;: \u0026#34;\u0026#39;epoch\u0026#39;: ([0-9]+(.|e\\-)[0-9]+),?\u0026#34;}] Configure profiling rules We specify the following rules:\n loss_not_decreasing: checks if loss is decreasing and triggers if the loss has not decreased by a certain percentage in the last few iterations LowGPUUtilization: checks if GPU is under-utilizated ProfilerReport: runs the entire set of performance rules and create a final output report with further insights and recommendations.\n# Configure a Profiler rule object rules = [ Rule.sagemaker(rule_configs.loss_not_decreasing()), ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()), ProfilerRule.sagemaker(rule_configs.ProfilerReport()) ]  The following configuration will capture system metrics at 500 milliseconds. The system metrics include utilization per CPU, GPU, memory utilization per CPU, GPU as well I/O and network.\nDebugger will capture detailed profiling information from step 5 to step 15. This information includes Horovod metrics, dataloading, preprocessing, operators running on CPU and GPU.\n# Specify a profiler configuration profiler_config = ProfilerConfig( system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10) )# s3 uri where our checkpoints will be uploaded during training job_name = f\u0026#39;huggingface-sm-{time.strftime(\u0026#34;%Y-%m-%d-%H-%M-%S\u0026#34;, time.gmtime())}\u0026#39; checkpoint_s3_uri = f\u0026#39;s3://{bucket}/{prefix}/{job_name}/checkpoints\u0026#39; output_path = f\u0026#39;s3://{bucket}/{prefix}/training_jobs\u0026#39; # create the Estimator huggingface_estimator = HuggingFace(entry_point = \u0026#39;train.py\u0026#39;, source_dir = \u0026#39;src\u0026#39;, output_path = f\u0026#39;{output_path}/\u0026#39;, code_location = output_path, role = role, base_job_name = job_name, checkpoint_s3_uri = checkpoint_s3_uri, instance_type = \u0026#39;ml.p3.2xlarge\u0026#39;, instance_count = 1, transformers_version = \u0026#39;4.6\u0026#39;, pytorch_version = \u0026#39;1.7\u0026#39;, py_version = \u0026#39;py36\u0026#39;, hyperparameters = hyperparameters, metric_definitions = metric_definitions, # Debugger-specific parameters profiler_config = profiler_config, rules = rules ) Execute the fine-tuning Job data = {\u0026#39;train\u0026#39;: f\u0026#34;s3://{bucket}/{prefix}/data/train.csv\u0026#34;, \u0026#39;test\u0026#39;: f\u0026#34;s3://{bucket}/{prefix}/data/validate.csv\u0026#34; } huggingface_estimator.fit(data, wait=True) Output: Accessing Training Metrics # Captured metrics can be accessed as a Pandas dataframe training_job_name = huggingface_estimator.latest_training_job.name print(f\u0026#34;Training jobname: {training_job_name}\u0026#34;) df = TrainingJobAnalytics(training_job_name=training_job_name).dataframe() df Output: Analyze Profiling Data While the training is still in progress you can visualize the performance data in SageMaker Studio or in the notebook. Debugger provides utilities to plot system metrics in form of timeline charts or heatmaps. In the following code cell we plot the total CPU and GPU utilization as timeseries charts. To visualize other metrics such as I/O, memory, network you simply need to extend the list passed to select_dimension and select_events.\nsession = boto3.session.Session() region = session.region_name tj = TrainingJob(training_job_name, region) tj.wait_for_sys_profiling_data_to_be_available() Download profiling data system_metrics_reader = tj.get_systems_metrics_reader() system_metrics_reader.refresh_event_file_list() view_timeline_charts = TimelineCharts( system_metrics_reader, framework_metrics_reader=None, select_dimensions=[\u0026#34;CPU\u0026#34;, \u0026#34;GPU\u0026#34;], select_events=[\u0026#34;total\u0026#34;], ) Output: Download Debugger Profling Report The profiling report rule will create an html report profiler-report.html with a summary of builtin rules and recommenades of next steps. You can find this report in your S3 bucket.\nrule_output_path = huggingface_estimator.output_path + huggingface_estimator.latest_training_job.job_name + \u0026#34;/rule-output\u0026#34; print(f\u0026#34;You will find the profiler report in {rule_output_path}\u0026#34;)sagemaker_session.download_data(path = \u0026#39;.\u0026#39;, bucket = bucket, key_prefix = f\u0026#39;{prefix}/training_jobs/{huggingface_estimator.latest_training_job.job_name}/rule-output/ProfilerReport/profiler-output/profiler-report.html\u0026#39;) Viewing profiling report in SageMaker Studio Deploying the endpoint %%time endpoint_name = f\u0026#39;huggingface-finetune-{time.strftime(\u0026#34;%Y-%m-%d-%H-%M-%S\u0026#34;, time.gmtime())}\u0026#39; # create Hugging Face Model Class huggingface_model = HuggingFaceModel( model_data = huggingface_estimator.model_data, # S3 path to your trained sagemaker model role = role, # IAM role with permissions to create an Endpoint transformers_version = \u0026#39;4.6\u0026#39;, pytorch_version = \u0026#39;1.7\u0026#39;, py_version = \u0026#39;py36\u0026#39; ) # deploy model to SageMaker Inference predictor = huggingface_model.deploy( initial_instance_count = 1, instance_type = \u0026#34;ml.m5.xlarge\u0026#34;, endpoint_name = endpoint_name ) Evaluate predictions on the test set test = pd.read_csv(\u0026#39;data/test.csv\u0026#39;) test.head()%%time pred_list = [] test_small = test # Predicting only on 100 rows, change this to predict on a larger number of rows for idx, row in test_small.iterrows(): payload = {\u0026#34;inputs\u0026#34;: row[\u0026#39;text\u0026#39;]} pred = predictor.predict(payload)[0] # rename label to prediction pred[\u0026#39;prediction\u0026#39;] = pred.pop(\u0026#39;label\u0026#39;) # convert prediction value to int pred[\u0026#39;prediction\u0026#39;] = int(pred[\u0026#39;prediction\u0026#39;].replace(\u0026#39;LABEL_\u0026#39;, \u0026#39;\u0026#39;)) pred_list.append(pred)test_small[\u0026#39;prediction\u0026#39;] = pred_list df_test = pd.concat([test_small.drop([\u0026#39;prediction\u0026#39;], axis=1), test_small[\u0026#39;prediction\u0026#39;].apply(pd.Series)], axis=1)print(classification_report(df_test[\u0026#39;label\u0026#39;], df_test[\u0026#39;prediction\u0026#39;]))from sklearn.metrics import confusion_matrix import matplotlib.pyplot as plt %matplotlib inline import seaborn as sn cm = confusion_matrix(y_true=df_test[\u0026#39;label\u0026#39;], y_pred=df_test[\u0026#39;prediction\u0026#39;]) cm = cm.astype(\u0026#39;float\u0026#39;) / cm.sum(axis=1)[:, np.newaxis] sn.set(rc={\u0026#39;figure.figsize\u0026#39;: (11.7,8.27)}) sn.set(font_scale=1.4) # for label size sn.heatmap(cm, annot=True, annot_kws={\u0026#34;size\u0026#34;: 10}) # font size plt.title(\u0026#39;Confusion Matrix of the Test Data\u0026#39;, fontsize=14) plt.ylabel(\u0026#39;Real Class\u0026#39;, fontsize=12) plt.xlabel(\u0026#39;Predicted Class\u0026#39;, fontsize=12) plt.show() Output: Invoke the endpoint with the Python SDK # client = boto3.client(\u0026#39;sagemaker\u0026#39;) # endpoint = client.list_endpoints()[\u0026#39;Endpoints\u0026#39;]review_num = 15 payload = {\u0026#34;inputs\u0026#34;: [test[\u0026#39;text\u0026#39;].iloc[review_num]]} predictor = HuggingFacePredictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session ) result = predictor.predict(data=payload)[0] print(f\u0026#34;Predicted \\033[1m{result[\u0026#39;label\u0026#39;]}\\033[0m with score of \\033[1m{round(result[\u0026#39;score\u0026#39;], 2)}\\033[0m. Real label is \\033[1m{test[\u0026#39;label\u0026#39;].iloc[review_num]}\\033[0m. Full sentence:\\n\\n{test[\u0026#39;text\u0026#39;].iloc[review_num]}\u0026#34;) Output: Alternative: invoke the endpoint with boto3 client = boto3.client(\u0026#39;sagemaker-runtime\u0026#39;) payload = {\u0026#34;inputs\u0026#34;: [test[\u0026#39;text\u0026#39;].iloc[review_num]]} user_encode_data = json.dumps(payload).encode(\u0026#39;utf-8\u0026#39;) response = client.invoke_endpoint(EndpointName=endpoint_name, Body=user_encode_data, ContentType=\u0026#39;application/json\u0026#39; ) result = json.loads(response[\u0026#39;Body\u0026#39;].read())[0] print(f\u0026#34;Predicted \\033[1m{result[\u0026#39;label\u0026#39;]}\\033[0m with score of \\033[1m{round(result[\u0026#39;score\u0026#39;], 2)}\\033[0m. Real label is \\033[1m{test[\u0026#39;label\u0026#39;].iloc[review_num]}\\033[0m. Full sentence:\\n\\n{test[\u0026#39;text\u0026#39;].iloc[review_num]}\u0026#34;) Output: Clean up Make sure you delete the SageMaker endpoints and S3 artifacts to clean up.\nDelete endpoint:\n# predictor.delete_endpoint() Delete S3 artifacts:\n# s3 = boto3.resource(\u0026#39;s3\u0026#39;) # bucket = s3.Bucket(bucket) # bucket.objects.filter(Prefix=f\u0026#34;{prefix}/\u0026#34;).delete() # print(f\u0026#34;\\nDeleted contents of {bucket}/{prefix}\u0026#34;)"
},
{
	"uri": "/3_clean-up/cleanup.html",
	"title": "Delete all resources",
	"tags": [],
	"description": "",
	"content": " This workshop creates the following resources:\n SageMaker Endpoints S3 objects SageMaker apps  If you completed section 2.2, the \u0026ldquo;Delete resources\u0026rdquo; section at the end deletes running SageMaker Endpoints and all S3 objects created during the workshop.\nYou can also delete the endpoints by navigating to AWS Console \u0026gt; Amazon SageMaker. In the left menu click on Inference \u0026gt; Endpoints. Select the endpoint you want to delete and click on Action \u0026gt; Delete.\nFor additional information about deleting SageMaker resources, please visit the following documentation page: https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html\nDeleting SageMaker Studio apps Using the AWS Console SageMaker Studio also creates apps such as JupyterServer (used to run notebooks), DataWrangler and Debugger which run on EC2 instances. Use the following instructions to shutdown running apps:\nNavigate to AWS Console \u0026gt; Amazon SageMaker \u0026gt; Amazon SageMaker Studio. This will open up the SageMaker Studio Control Panel. Click on the Studio user who’s resources you want to delete.\nUnder User Details click on “Delete app” to delete all running apps. Keep the “default” App if you want to continue working with SageMaker Studio and want to launch new notebooks.\nUsing the SageMaker Studio In SageMaker Studio Notebook, click on the running apps menu which is 3rd from the top. Click on all the power buttons to shut down apps. Keep the running instances if you want to continue working on SageMaker Notebook.\nFor more information about deleting Studio resources, Studio domain and how to delete resources using AWS CLI visit the following documentation page: https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-delete-domain.html?icmpid=docs_sagemaker_console_studio\n"
},
{
	"uri": "/2_build-train-tune-deploy.html",
	"title": "2. Amazon SageMaker and HuggingFace library",
	"tags": [],
	"description": "",
	"content": " In this section you\u0026rsquo;ll learn how to build train and tune your machine learning models. You will cover:  Preparing your training, validation and test sets Preparing a HuggingFace Transformers fine-tuning script Using Amazon SageMaker and HuggingFace to fine-tune models on your datasets Using Amazon SageMaker Debugger to profile your training jobs Deploying NLP models to endpoints using SageMaker and evaluating them  "
},
{
	"uri": "/appendix/resources.html",
	"title": "Technical papers",
	"tags": [],
	"description": "",
	"content": " 1. Whitepaper on AI Fairness https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf 2. Paper on Debugging ML models https://www.amazon.science/publications/amazon-sagemaker-debugger-a-system-for-real-time-insights-into-machine-learning-model-training "
},
{
	"uri": "/appendix/blogposts_videos.html",
	"title": "Blogposts and videos",
	"tags": [],
	"description": "",
	"content": " 1. ML blog posts https://medium.com/@shashankprasanna 2. AWS Blog posts https://aws.amazon.com/blogs/machine-learning/ "
},
{
	"uri": "/3_clean-up.html",
	"title": "3. Clean up resources",
	"tags": [],
	"description": "",
	"content": "In this section you\u0026rsquo;ll find instructions to clean up resources used for this workshop.\n"
},
{
	"uri": "/appendix.html",
	"title": "Appendix",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]